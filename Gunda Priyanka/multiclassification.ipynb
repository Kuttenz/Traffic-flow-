{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset\n",
        "!unzip -q stanford-dogs-dataset.zip -d stanford-dogs-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKPWlzGu1_ae",
        "outputId": "3ea3939b-1b2a-4962-e56a-0353d345330a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
            "License(s): other\n",
            "Downloading stanford-dogs-dataset.zip to /content\n",
            "100% 748M/750M [00:32<00:00, 23.2MB/s]\n",
            "100% 750M/750M [00:32<00:00, 24.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls stanford-dogs-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8zN8s6x1_cy",
        "outputId": "cf228a04-4941-4848-adde-22d2aacf51f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "FDtKgdki1_fb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "x5N693ng1_hu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'stanford-dogs-dataset'\n",
        "images_path = os.path.join(dataset_path, \"images\")\n",
        "annotations_path = os.path.join(dataset_path, \"annotation\")"
      ],
      "metadata": {
        "id": "MYAfLcEk1_kQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "dataset_dir = 'stanford-dogs-dataset/images/Images'\n",
        "annotations_dir = 'stanford-dogs-dataset/annotations/Annotation'\n",
        "filtered_dir = 'filtered-dogs'\n",
        "filtered_annotations_dir = os.path.join(filtered_dir, 'Annotation')\n",
        "filtered_images_dir = os.path.join(filtered_dir, 'Images')\n",
        "\n",
        "# Ensure the filtered directory is clean\n",
        "if os.path.exists(filtered_dir):\n",
        "    shutil.rmtree(filtered_dir)\n",
        "os.makedirs(filtered_annotations_dir)\n",
        "os.makedirs(filtered_images_dir)\n",
        "\n",
        "# List all species\n",
        "all_species = os.listdir(dataset_dir)\n",
        "print(f'Total species: {len(all_species)}')\n",
        "\n",
        "# Randomly select 10 species\n",
        "selected_species = random.sample(all_species, 10)\n",
        "print(f'Selected species: {selected_species}')\n",
        "\n",
        "# Copy selected species to the filtered directory\n",
        "for species in selected_species:\n",
        "    species_image_path = os.path.join(dataset_dir, species)\n",
        "    species_annotation_path = os.path.join(annotations_dir, species)\n",
        "    target_image_path = os.path.join(filtered_images_dir, species)\n",
        "    target_annotation_path = os.path.join(filtered_annotations_dir, species)\n",
        "\n",
        "    # Copy image files\n",
        "    shutil.copytree(species_image_path, target_image_path)\n",
        "\n",
        "    # Copy annotation files\n",
        "    shutil.copytree(species_annotation_path, target_annotation_path)\n",
        "\n",
        "print(\"Selected species images and annotations have been copied to the filtered directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKaN83jE1_mv",
        "outputId": "13ac649b-5ccf-4cec-cacc-e1dcb32efcc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total species: 120\n",
            "Selected species: ['n02086646-Blenheim_spaniel', 'n02112137-chow', 'n02098413-Lhasa', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02096051-Airedale', 'n02087394-Rhodesian_ridgeback', 'n02090721-Irish_wolfhound', 'n02099712-Labrador_retriever', 'n02091134-whippet']\n",
            "Selected species images and annotations have been copied to the filtered directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.2, 1.0],\n",
        "    channel_shift_range=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "hnoEp8J51_pc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = filtered_images_dir"
      ],
      "metadata": {
        "id": "0i9JIUJc1_tC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HT743wm2Afe",
        "outputId": "e8ff437d-09b7-44e7-94cd-77b5e4a5acee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1471 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u5cBXrY2AiE",
        "outputId": "4a1707f1-8b91-4d0b-ba2c-44a7bf295819"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 364 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9xnwQ9i2Ak-",
        "outputId": "b4e7d895-4b02-4c4a-ce86-3e8bcd81b1ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1835 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total training samples: {train_generator.samples}')\n",
        "print(f'Total validation samples: {validation_generator.samples}')\n",
        "print(f'Total test samples: {test_generator.samples}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHq-c7Bv2Any",
        "outputId": "ceeeb547-183d-45ec-b002-46379c1b43b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 1471\n",
            "Total validation samples: 364\n",
            "Total test samples: 1835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "Ojjes_0v2ArJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "e6eqQGYq4FTg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bhxIyssX4FQF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "KiQA2CrU4FNS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLKPfw_4FKa",
        "outputId": "1d8d539a-3629-4d26-a416-69f961c4f45f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 227s 10s/step - loss: 4.4095 - accuracy: 0.0945 - val_loss: 3.9504 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 233s 11s/step - loss: 3.6279 - accuracy: 0.1144 - val_loss: 3.3190 - val_accuracy: 0.1375\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 224s 10s/step - loss: 3.1121 - accuracy: 0.1130 - val_loss: 2.9168 - val_accuracy: 0.1250\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 243s 11s/step - loss: 2.7946 - accuracy: 0.1237 - val_loss: 2.6777 - val_accuracy: 0.1250\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 226s 10s/step - loss: 2.6004 - accuracy: 0.1251 - val_loss: 2.5264 - val_accuracy: 0.1375\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 223s 10s/step - loss: 2.4744 - accuracy: 0.1500 - val_loss: 2.4372 - val_accuracy: 0.1844\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 231s 10s/step - loss: 2.4092 - accuracy: 0.1485 - val_loss: 2.3698 - val_accuracy: 0.1781\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 222s 10s/step - loss: 2.3396 - accuracy: 0.1770 - val_loss: 2.3294 - val_accuracy: 0.2094\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 224s 10s/step - loss: 2.3202 - accuracy: 0.1663 - val_loss: 2.2978 - val_accuracy: 0.1906\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 233s 10s/step - loss: 2.2864 - accuracy: 0.1805 - val_loss: 2.2759 - val_accuracy: 0.1719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxiSbfGb4FHu",
        "outputId": "a40fbfff-166d-48b8-bffd-d19f71ff31ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 77s 3s/step - loss: 2.2855 - accuracy: 0.1777\n",
            "Test accuracy: 0.17765668034553528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xf4n0xxO4FEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAfKrL-X4FBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kChNX3Jq4E-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Orols58o4E7u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}