{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvatqVLp1-Zc",
        "outputId": "0451d378-4fc3-4b86-e240-73cb6423f405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
            "License(s): other\n",
            "Downloading stanford-dogs-dataset.zip to /content\n",
            " 98% 737M/750M [00:04<00:00, 197MB/s]\n",
            "100% 750M/750M [00:04<00:00, 189MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset\n",
        "!unzip -q stanford-dogs-dataset.zip -d stanford-dogs-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMetxBFO1_1f",
        "outputId": "8b3ee7a0-6d47-4df4-a849-08faa0e28e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "annotations  images\n"
          ]
        }
      ],
      "source": [
        "!ls stanford-dogs-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgX5uRIs2D5_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqoNV3MQ2Jr-"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR4ooIqp2J5L"
      },
      "outputs": [],
      "source": [
        "# Define paths (update these paths based on your setup)\n",
        "dataset_path = 'stanford-dogs-dataset'\n",
        "images_path = os.path.join(dataset_path, \"images\")\n",
        "annotations_path = os.path.join(dataset_path, \"annotation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPleB0kJ3NZU",
        "outputId": "fdd31795-cf11-4e49-a99b-a8b20684f1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total species: 120\n",
            "Selected species: ['n02100236-German_short-haired_pointer', 'n02113712-miniature_poodle', 'n02091032-Italian_greyhound', 'n02089867-Walker_hound', 'n02108915-French_bulldog']\n",
            "Selected species images and annotations have been copied to the filtered directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "dataset_dir = 'stanford-dogs-dataset/images/Images'\n",
        "annotations_dir = 'stanford-dogs-dataset/annotations/Annotation'\n",
        "filtered_dir = 'filtered-dogs'\n",
        "filtered_annotations_dir = os.path.join(filtered_dir, 'Annotation')\n",
        "filtered_images_dir = os.path.join(filtered_dir, 'Images')\n",
        "\n",
        "# Ensure the filtered directory is clean\n",
        "if os.path.exists(filtered_dir):\n",
        "    shutil.rmtree(filtered_dir)\n",
        "os.makedirs(filtered_annotations_dir)\n",
        "os.makedirs(filtered_images_dir)\n",
        "\n",
        "# List all species\n",
        "all_species = os.listdir(dataset_dir)\n",
        "print(f'Total species: {len(all_species)}')\n",
        "\n",
        "# Randomly select 5 species\n",
        "selected_species = random.sample(all_species, 5)\n",
        "print(f'Selected species: {selected_species}')\n",
        "\n",
        "# Copy selected species to the filtered directory\n",
        "for species in selected_species:\n",
        "    species_image_path = os.path.join(dataset_dir, species)\n",
        "    species_annotation_path = os.path.join(annotations_dir, species)\n",
        "    target_image_path = os.path.join(filtered_images_dir, species)\n",
        "    target_annotation_path = os.path.join(filtered_annotations_dir, species)\n",
        "\n",
        "    # Copy image files\n",
        "    shutil.copytree(species_image_path, target_image_path)\n",
        "\n",
        "    # Copy annotation files\n",
        "    shutil.copytree(species_annotation_path, target_annotation_path)\n",
        "\n",
        "print(\"Selected species images and annotations have been copied to the filtered directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI_3kQIo3cHH"
      },
      "outputs": [],
      "source": [
        "# Data generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.2, 1.0],\n",
        "    channel_shift_range=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_Keq88A3eRa"
      },
      "outputs": [],
      "source": [
        "images_dir = filtered_images_dir  # Use the filtered images directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpI1Z2px3ePS",
        "outputId": "d12d14f2-e900-4a2a-db11-a8c092162688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 643 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wwB5xXy3eNR",
        "outputId": "b3e74d5d-8727-4435-b567-bde94b196aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 158 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_generator = datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsAomPpN3eLH",
        "outputId": "6953ea7c-002a-4f0b-c594-a0c581158bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 801 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    images_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRpDRHb03eI9",
        "outputId": "f7b6ad5f-e770-4682-a9a9-09ed88ef6f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 643\n",
            "Total validation samples: 158\n",
            "Total test samples: 801\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the generators\n",
        "print(f'Total training samples: {train_generator.samples}')\n",
        "print(f'Total validation samples: {validation_generator.samples}')\n",
        "print(f'Total test samples: {test_generator.samples}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pp2SRwN3eEw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYVuc6y14RyT"
      },
      "outputs": [],
      "source": [
        "# Define a custom CNN architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTHEa-hS4Ruq"
      },
      "outputs": [],
      "source": [
        "# Compile the model with a smaller learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwS4jNUS4RtJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrc87woa4RrF",
        "outputId": "1fa2f507-035c-4ebb-aa29-a856f829e359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 81s 8s/step - loss: 1.6238 - accuracy: 0.2850 - val_loss: 1.6080 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.6108 - accuracy: 0.2815 - val_loss: 1.5936 - val_accuracy: 0.2891\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.6011 - accuracy: 0.2867 - val_loss: 1.5961 - val_accuracy: 0.2656\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 76s 8s/step - loss: 1.6090 - accuracy: 0.2729 - val_loss: 1.6110 - val_accuracy: 0.2891\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5990 - accuracy: 0.2660 - val_loss: 1.5979 - val_accuracy: 0.2578\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 75s 8s/step - loss: 1.6111 - accuracy: 0.2729 - val_loss: 1.6408 - val_accuracy: 0.2344\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 77s 7s/step - loss: 1.6218 - accuracy: 0.2608 - val_loss: 1.5778 - val_accuracy: 0.3438\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 84s 8s/step - loss: 1.6100 - accuracy: 0.2672 - val_loss: 1.5687 - val_accuracy: 0.2812\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5942 - accuracy: 0.3022 - val_loss: 1.6060 - val_accuracy: 0.3438\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5956 - accuracy: 0.2971 - val_loss: 1.5722 - val_accuracy: 0.3750\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.5929 - accuracy: 0.3040 - val_loss: 1.5761 - val_accuracy: 0.2891\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 76s 7s/step - loss: 1.5798 - accuracy: 0.3195 - val_loss: 1.5429 - val_accuracy: 0.3203\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5974 - accuracy: 0.2712 - val_loss: 1.5534 - val_accuracy: 0.3281\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5964 - accuracy: 0.2919 - val_loss: 1.5974 - val_accuracy: 0.3438\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.5878 - accuracy: 0.3005 - val_loss: 1.5988 - val_accuracy: 0.3359\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 77s 7s/step - loss: 1.5947 - accuracy: 0.2884 - val_loss: 1.5706 - val_accuracy: 0.3906\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5907 - accuracy: 0.3092 - val_loss: 1.5609 - val_accuracy: 0.3281\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.6018 - accuracy: 0.2746 - val_loss: 1.5570 - val_accuracy: 0.3984\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5706 - accuracy: 0.3437 - val_loss: 1.6303 - val_accuracy: 0.2656\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 73s 7s/step - loss: 1.5919 - accuracy: 0.2936 - val_loss: 1.5914 - val_accuracy: 0.2422\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 73s 7s/step - loss: 1.5841 - accuracy: 0.3178 - val_loss: 1.5625 - val_accuracy: 0.3438\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.5934 - accuracy: 0.3143 - val_loss: 1.5906 - val_accuracy: 0.2891\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 73s 7s/step - loss: 1.5856 - accuracy: 0.3143 - val_loss: 1.5558 - val_accuracy: 0.2891\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5795 - accuracy: 0.3264 - val_loss: 1.5644 - val_accuracy: 0.2969\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 92s 9s/step - loss: 1.5783 - accuracy: 0.3282 - val_loss: 1.5957 - val_accuracy: 0.3047\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 82s 8s/step - loss: 1.6026 - accuracy: 0.2919 - val_loss: 1.5710 - val_accuracy: 0.3594\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5867 - accuracy: 0.3541 - val_loss: 1.5673 - val_accuracy: 0.3516\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 73s 7s/step - loss: 1.5801 - accuracy: 0.3454 - val_loss: 1.5357 - val_accuracy: 0.3750\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.5797 - accuracy: 0.3420 - val_loss: 1.5525 - val_accuracy: 0.3750\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5822 - accuracy: 0.3143 - val_loss: 1.5830 - val_accuracy: 0.3047\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 75s 7s/step - loss: 1.5970 - accuracy: 0.3057 - val_loss: 1.5696 - val_accuracy: 0.2656\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5988 - accuracy: 0.2953 - val_loss: 1.5724 - val_accuracy: 0.3281\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 85s 8s/step - loss: 1.5991 - accuracy: 0.2815 - val_loss: 1.5881 - val_accuracy: 0.3047\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5912 - accuracy: 0.2712 - val_loss: 1.5855 - val_accuracy: 0.3203\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5727 - accuracy: 0.3109 - val_loss: 1.5631 - val_accuracy: 0.3594\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.5699 - accuracy: 0.3368 - val_loss: 1.5609 - val_accuracy: 0.3594\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5682 - accuracy: 0.3161 - val_loss: 1.5318 - val_accuracy: 0.3516\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5854 - accuracy: 0.3402 - val_loss: 1.5153 - val_accuracy: 0.4141\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 77s 7s/step - loss: 1.5795 - accuracy: 0.3264 - val_loss: 1.5953 - val_accuracy: 0.2578\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 84s 8s/step - loss: 1.5741 - accuracy: 0.3143 - val_loss: 1.6018 - val_accuracy: 0.2500\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5904 - accuracy: 0.3161 - val_loss: 1.5530 - val_accuracy: 0.3750\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.6190 - accuracy: 0.2867 - val_loss: 1.6272 - val_accuracy: 0.2812\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.6025 - accuracy: 0.2902 - val_loss: 1.5947 - val_accuracy: 0.3203\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5858 - accuracy: 0.3282 - val_loss: 1.5309 - val_accuracy: 0.3672\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 81s 8s/step - loss: 1.5853 - accuracy: 0.3297 - val_loss: 1.5558 - val_accuracy: 0.3281\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.6021 - accuracy: 0.2936 - val_loss: 1.5900 - val_accuracy: 0.2891\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 94s 9s/step - loss: 1.5465 - accuracy: 0.3594 - val_loss: 1.5459 - val_accuracy: 0.3125\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 74s 7s/step - loss: 1.5621 - accuracy: 0.3316 - val_loss: 1.5367 - val_accuracy: 0.3828\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 76s 8s/step - loss: 1.5708 - accuracy: 0.3368 - val_loss: 1.5637 - val_accuracy: 0.3281\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.5723 - accuracy: 0.3506 - val_loss: 1.5298 - val_accuracy: 0.3906\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "32wAO0oV4RpH",
        "outputId": "92cb9b5a-2ee0-4c90-f776-fc7dfe0c9eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 25s 2s/step - loss: 1.5742 - accuracy: 0.3608\n",
            "Test accuracy: 0.36079901456832886\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVImZx6X4RnD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTrG1UZi4Rk-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}